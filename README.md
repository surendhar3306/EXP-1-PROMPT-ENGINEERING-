# EXP-1-PROMPT-ENGINEERING-

## Aim: 
Comprehensive Report on the Fundamentals of Generative AI and Large Language Models (LLMs)
Experiment: Develop a comprehensive report for the following exercises:

Explain the foundational concepts of Generative AI.
Focusing on Generative AI architectures. (like transformers).
Generative AI applications.
Generative AI impact of scaling in LLMs.

## Algorithm:
Input Understanding

Read the assignment prompt carefully.

Identify key tasks:

Explain foundational concepts of Generative AI.

Explain architectures (focus on Transformers).

Explain applications of Generative AI.

Explain impact of scaling in Large Language Models.

Knowledge Gathering

Recall definitions, principles, and categories of generative AI.

Recall architecture components of Transformers.

Recall real-world applications (text, code, image, multimodal).

Recall scaling laws, benefits, risks, and limitations.

Report Development

Organize content into clear sections (Concepts → Architecture → Applications → Scaling).

Use simple technical language, bullet points, and short examples.

Ensure each section connects logically to the next.

Verification

Check that all four tasks from the prompt are answered.

Ensure flow is comprehensive and concise.
## Output
Foundations: Generative AI creates new data (text, image, code) by learning data distributions.

Architectures: Transformers (self-attention, embeddings, decoder-only/encoder-decoder) power modern LLMs.

Applications: Chatbots, code assistants, image generation, enterprise automation.

Scaling Impact: Bigger models improve reasoning/emergent skills but increase cost, latency, and risks.
## Result
A concise report covering Generative AI basics, transformer architecture, real-world applications, and scaling effects in LLMs.
